{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.15.0\n",
    "# !pip install gym==0.29.1\n",
    "# !pip install keras\n",
    "# !pip install keras-rl2\n",
    "# %pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ipykernel\n",
    "# %pip install --upgrade nbformat\n",
    "# %pip install stable-baselines3[extra]\n",
    "# %pip install gymnasium==0.29.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install stable-baselines3 plotly numpy pandas\n",
    "# %pip install ipywidgets\n",
    "# %pip install pandas_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import logging\n",
    "import math\n",
    "from model_config import Path\n",
    "import os\n",
    "import torch\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gym import Env\n",
    "from gymnasium import spaces\n",
    "from gymnasium.utils import seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decimal\n",
    "decimal.getcontext().prec = 28  # Increase precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Используем GPU\n",
    "    print(\"CUDA доступна. Работаем на GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")   # Используем CPU\n",
    "    print(\"CUDA не доступна. Работаем на CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основано на Model 2, Отличия:\n",
    "- Подаем на вход 3 дополнительные фичи:\n",
    "    - tokens_held\n",
    "    - balance\n",
    "    - net_worth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 48\n",
    "nb_steps = 80000\n",
    "\n",
    "model_num = 9\n",
    "data_num = 1\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed= seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dataset_file(dnum, folder=\"data\"):\n",
    "    pattern = f\"dataset_{dnum}D_*.csv\"\n",
    "    for filename in os.listdir(folder):\n",
    "        if fnmatch.fnmatch(filename, pattern):\n",
    "            return os.path.join(folder, filename)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = find_dataset_file(data_num, folder= Path[\"processed\"])\n",
    "print(data_path)\n",
    "df = pd.read_csv(data_path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_close_prices = df[df['Close_orig'] == 0]\n",
    "print(f\"Number of zero 'Close' prices after scaling: {len(zero_close_prices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = df['Asset_ID_encoded'].unique()\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df['Asset_ID_encoded'].value_counts()\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_asset_ids(df: pd.DataFrame, test_asset_ids: list):\n",
    "    test_df = df[df['Asset_ID_encoded'].isin(test_asset_ids)]\n",
    "    train_df = df[~df['Asset_ID_encoded'].isin(test_asset_ids)]\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_asset_ids = [21, 22, 23, 24, 25]\n",
    "train_df, test_df = split_by_asset_ids(df = df, test_asset_ids = test_asset_ids)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Testing data shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Environment for training an agent to trade on the exchange using a continuous action space.\n",
    "    \"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, df, mode):\n",
    "        super(TradingEnv, self).__init__()\n",
    "\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.total_steps = len(self.df) - 1\n",
    "        self.window_length = window_length\n",
    "        self.mode = mode # test or train\n",
    "\n",
    "        self.asset_start_indices = self._find_asset_start_indices()\n",
    "        print(self.asset_start_indices)\n",
    "\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
    "\n",
    "        num_features = len(self.df.columns) - 1 + 3 # Вычли Close_orig\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(self.window_length, num_features), dtype=np.float32)\n",
    "\n",
    "        self.fee_cost = 0.001\n",
    "        self.initial_balance = 1000  # Starting balance\n",
    "        self.balance = self.initial_balance\n",
    "        self.net_worth = self.initial_balance\n",
    "        self.fut_net_worth = self.initial_balance\n",
    "\n",
    "        self.reward = 0\n",
    "        self.current_step = self.window_length\n",
    "        self.current_price = 0\n",
    "        self.tokens_held = 0\n",
    "        self.total_shares_sold = 0\n",
    "        self.total_sales_value = 0\n",
    "\n",
    "        self.now_token = (self.df.loc[self.current_step, 'Asset_ID_encoded'] - 1)\n",
    "        print(self.now_token)\n",
    "        self.prev_token = self.now_token\n",
    "\n",
    "        self.hist = {\n",
    "            \"current_step\": [],\n",
    "            'balance': [],\n",
    "            'net_worth': [],\n",
    "            'tokens_held': [],\n",
    "            \"token\": [],\n",
    "            \"current_price\": [],\n",
    "            \"reward\": [],\n",
    "            \"action\": [],\n",
    "            'total_shares_sold': [],\n",
    "            'total_sales_value': [],\n",
    "        }\n",
    "\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "\n",
    "        if self.logger.hasHandlers():\n",
    "            self.logger.handlers.clear()\n",
    "\n",
    "        log_file = Path[\"train_log\"](model_num, data_num + 1)\n",
    "        file_handler = logging.FileHandler(log_file)\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        file_handler.setFormatter(formatter)\n",
    "\n",
    "        self.logger.addHandler(file_handler)\n",
    "        logging.getLogger().handlers = []\n",
    "\n",
    "\n",
    "    def _find_asset_start_indices(self):\n",
    "        \"\"\"\n",
    "        Find the indices in the DataFrame where a new asset starts.\n",
    "        \"\"\"\n",
    "        asset_ids = self.df['Asset_ID_encoded']\n",
    "        start_indices = {asset_ids[0]:0}\n",
    "        for i in range(1, len(asset_ids)):\n",
    "            if asset_ids[i] != asset_ids[i - 1]:\n",
    "                start_indices[asset_ids[i]] = i\n",
    "\n",
    "        return start_indices\n",
    "\n",
    "\n",
    "    def reset(self, seed = seed, options=None, reset_hist=False):\n",
    "        super().reset(seed= seed)\n",
    "        self.logger.info(\"Environment reset\")\n",
    "\n",
    "        # Existing reset logic\n",
    "        self.balance = self.initial_balance\n",
    "        self.net_worth = self.initial_balance\n",
    "        self.fut_net_worth = self.initial_balance\n",
    "        self.tokens_held = 0\n",
    "        self.total_shares_sold = 0\n",
    "        self.total_sales_value = 0\n",
    "\n",
    "        # Move to the next asset's starting index\n",
    "        self.now_token += 1\n",
    "        if self.now_token not in self.asset_start_indices:\n",
    "            if self.mode == \"train\":\n",
    "                self.now_token = list(self.asset_start_indices.keys())[0]  # Loop back to the first asset\n",
    "            else:\n",
    "                return None, None\n",
    "\n",
    "        self.current_step = self.asset_start_indices[self.now_token] + self.window_length\n",
    "        self.now_token = self.df.loc[self.current_step, 'Asset_ID_encoded']\n",
    "        self.prev_token = self.now_token\n",
    "\n",
    "        self.logger.info(f\"Starting new episode with token {self.now_token} at step {self.current_step}\")\n",
    "\n",
    "        # Reset hist only if reset_hist is True\n",
    "        if reset_hist:\n",
    "            self.hist = {\n",
    "                \"current_step\": [],\n",
    "                'balance': [],\n",
    "                'net_worth': [],\n",
    "                'tokens_held': [],\n",
    "                \"token\": [],\n",
    "                \"current_price\": [],\n",
    "                \"reward\": [],\n",
    "                \"action\": [],\n",
    "                'total_shares_sold': [],\n",
    "                'total_sales_value': [],\n",
    "            }\n",
    "\n",
    "        observation = self._next_observation()\n",
    "        info = {}\n",
    "        return observation, info\n",
    "\n",
    "\n",
    "    def _next_observation(self):\n",
    "        frame = self.df.drop(columns = ['Close_orig']).loc[self.current_step - self.window_length + 1:self.current_step]\n",
    "\n",
    "        # Нормализуем текущие значения переменных на каждом шаге\n",
    "        tokens_held_scaled = self.tokens_held \n",
    "        balance_scaled = self.balance\n",
    "        net_worth_scaled = self.net_worth\n",
    "\n",
    "        frame['tokens_held'] = tokens_held_scaled\n",
    "        frame['balance'] = balance_scaled\n",
    "        frame['net_worth'] = net_worth_scaled\n",
    "\n",
    "        obs = frame.values\n",
    "        return obs.astype(np.float32)\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        self.reward = 0\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        self.prev_token = self.now_token\n",
    "\n",
    "        if isinstance(action, (list, np.ndarray)):\n",
    "            action = action[0]\n",
    "\n",
    "        self.logger.info(f\"Step: {self.current_step}, Action taken: {action}\")\n",
    "        self._take_action(action)\n",
    "\n",
    "        self.current_step += 1  # Move to the next time step\n",
    "        \n",
    "        if self.current_step >= self.total_steps:\n",
    "            terminated = True\n",
    "        else:\n",
    "            self.now_token = self.df.loc[self.current_step, 'Asset_ID_encoded']\n",
    "            if self.now_token != self.prev_token:\n",
    "                self.logger.info(f\"Token change at step {self.current_step}: {self.prev_token} -> {self.now_token}\")\n",
    "                self.now_token -=1\n",
    "                terminated = True\n",
    "\n",
    "        if not terminated:\n",
    "            #  Теперь мы будем награждать модель используя данные за следующий шаг, а не предыдущий\n",
    "            self.future_price = self.df.loc[self.current_step, 'Close_orig'] \n",
    "            self.fut_net_worth = self.balance + self.tokens_held * self.future_price\n",
    "\n",
    "            if self.fut_net_worth != 0:\n",
    "                net_worth_change = (self.fut_net_worth * 100 / self.net_worth) - 100\n",
    "                price_change = (self.future_price * 100 / self.current_price) - 100\n",
    "                initial_change = self.net_worth / self.initial_balance\n",
    "                \n",
    "                if price_change > 0:\n",
    "                    self.reward += net_worth_change - (abs(abs(net_worth_change) - abs(price_change)) / 2)\n",
    "                else:\n",
    "                    self.reward += net_worth_change + (abs(abs(net_worth_change) - abs(price_change)) / 2)\n",
    "\n",
    "                if self.net_worth > self.initial_balance:\n",
    "                    self.reward += initial_change\n",
    "                else:\n",
    "                    self.reward += - (1 - initial_change)\n",
    "                \n",
    "                self.logger.info(f\"step: {self.current_price - 1}, net_worth_change: {net_worth_change}, price_change: {price_change}, initial_change: {initial_change}, reward: {self.reward}\")\n",
    "\n",
    "                if self.net_worth < self.initial_balance * 0.5: # Только во время тренировки штрафуем за проеб половины баланса\n",
    "                    if self.mode == \"train\":\n",
    "                        self.logger.info(\"Net worth dropped below 50% of initial balance.\")\n",
    "                        terminated = True\n",
    "            else:\n",
    "                self.logger.info(\"fut_net_worth == 0\")\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        info = {}\n",
    "\n",
    "        self.logger.info(f\"Net worth: {self.net_worth}, Balance: {self.balance}, Reward: {self.reward}\")\n",
    "\n",
    "        self.hist[\"current_step\"].append(self.current_step - 1)\n",
    "        self.hist[\"balance\"].append(self.balance)\n",
    "        self.hist[\"net_worth\"].append(self.net_worth)\n",
    "        self.hist[\"tokens_held\"].append(self.tokens_held)\n",
    "        self.hist[\"token\"].append(self.now_token)\n",
    "        self.hist[\"current_price\"].append(self.current_price)\n",
    "        self.hist[\"reward\"].append(self.reward)\n",
    "        self.hist[\"action\"].append(action)\n",
    "        self.hist[\"total_shares_sold\"].append(self.total_shares_sold)\n",
    "        self.hist[\"total_sales_value\"].append(self.total_sales_value)\n",
    "\n",
    "        return obs, self.reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "    def _take_action(self, action):\n",
    "        \"\"\"\n",
    "        Apply the continuous action to the current state.\n",
    "        \"\"\"\n",
    "        self.current_price = self.df.loc[self.current_step, 'Close_orig']\n",
    "\n",
    "        action = float(np.clip(action, -1, 1))\n",
    "\n",
    "        if action < 0:\n",
    "            proportion = -action  # Convert to positive\n",
    "            shares_to_sell = int(self.tokens_held * proportion)\n",
    "            self._sell(shares_to_sell)\n",
    "\n",
    "        elif action > 0:\n",
    "            proportion = action\n",
    "            self._buy(proportion)\n",
    "        else:\n",
    "            self.reward += -1\n",
    "            pass  \n",
    "\n",
    "        self.net_worth = self.balance + self.tokens_held * self.current_price\n",
    "\n",
    "\n",
    "    def _buy(self, proportion):\n",
    "        amount_to_spend = self.balance * proportion\n",
    "\n",
    "        shares_to_buy = int(amount_to_spend / (self.current_price * (1 + self.fee_cost)))\n",
    "\n",
    "        if shares_to_buy > 0:\n",
    "            total_cost = shares_to_buy * self.current_price\n",
    "            transaction_cost = total_cost * self.fee_cost\n",
    "            total_cost += transaction_cost\n",
    "\n",
    "            self.balance -= total_cost\n",
    "            self.tokens_held += shares_to_buy\n",
    "\n",
    "            self.logger.info(f\"Bought {shares_to_buy} shares at price {self.current_price}\")\n",
    "            self.logger.info(f\"Total cost: {total_cost}, Transaction cost: {transaction_cost}\")\n",
    "        else:\n",
    "            self.reward += -5\n",
    "            self.logger.info(\"Not enough balance to buy.\")\n",
    "\n",
    "\n",
    "    def _sell(self, shares_to_sell):\n",
    "        if shares_to_sell > self.tokens_held:\n",
    "            shares_to_sell = self.tokens_held  # Can't sell more than held\n",
    "\n",
    "        if shares_to_sell > 0:\n",
    "            total_sale = shares_to_sell * self.current_price\n",
    "            transaction_cost = total_sale * self.fee_cost\n",
    "            total_sale -= transaction_cost\n",
    "\n",
    "            self.balance += total_sale\n",
    "            self.tokens_held -= shares_to_sell\n",
    "            self.total_shares_sold += shares_to_sell\n",
    "            self.total_sales_value += total_sale\n",
    "\n",
    "            self.logger.info(f\"Sold {shares_to_sell} shares at price {self.current_price}\")\n",
    "            self.logger.info(f\"Total sale: {total_sale}, Transaction cost: {transaction_cost}\")\n",
    "        else:\n",
    "            self.reward += -5\n",
    "            self.logger.info(\"No shares to sell.\")\n",
    "\n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        profit = self.net_worth - self.initial_balance\n",
    "        print(f'Step: {self.current_step}')\n",
    "        print(f'Balance: {self.balance:.2f}')\n",
    "        print(f'Shares held: {self.tokens_held}')\n",
    "        print(f'Net worth: {self.net_worth:.2f}')\n",
    "        print(f'Profit: {profit:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = TradingEnv(train_df, mode = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = TradingEnv(test_df, mode = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_env(train_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisaton Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_close_by_asset(df, asset_id):\n",
    "    # Фильтрация данных по Asset_ID_encoded\n",
    "    asset_data = df[df['Asset_ID_encoded'] == asset_id]\n",
    "    \n",
    "    # Построение графика Close к индексу DataFrame\n",
    "    fig = px.line(asset_data, x=asset_data.index, y='Close_orig', \n",
    "                  title=f'Close Price for Asset ID {asset_id}', \n",
    "                  labels={'index': 'Index', 'Close': 'Close Price'})\n",
    "    \n",
    "    # Показать график\n",
    "    fig.show()\n",
    "    fig.write_html(Path[\"plots\"](model_num, data_num, \"close_by_asset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reward_data(df, token):\n",
    "    # Фильтрация данных по выбранному токену\n",
    "    token_data = df[df['token'] == token]\n",
    "    \n",
    "    # Вычисление среднего значения net_worth для данного токена\n",
    "    avg_net_worth = token_data['reward'].mean()\n",
    "\n",
    "    # Создание графика\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Линия net_worth\n",
    "    fig.add_trace(go.Scatter(x=token_data['current_step'], y=token_data['reward'], mode='lines', name='Reward'))\n",
    "\n",
    "    # Горизонтальная линия для среднего значения net_worth\n",
    "    fig.add_hline(y=avg_net_worth, line_color=\"red\", name=f'Average Reward = {avg_net_worth:.2f}')\n",
    "\n",
    "    # Настройка заголовков и осей\n",
    "    fig.update_layout(title=f'Reward and Average for {token}',\n",
    "                      xaxis_title='Current Step',\n",
    "                      yaxis_title='Reward')\n",
    "\n",
    "    # Показать график\n",
    "    fig.show()\n",
    "    fig.write_html(Path[\"plots\"](model_num, data_num, \"reward_by_asset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_price_change_by_asset(df, asset_id):\n",
    "    # Фильтрация данных по Asset_ID_encoded\n",
    "    asset_data = df[df['Asset_ID_encoded'] == asset_id].copy()\n",
    "    \n",
    "    # Вычисление процентного изменения цены (Close)\n",
    "    asset_data['Price_Change_Percent'] = asset_data['Close_orig'].pct_change() * 100\n",
    "    \n",
    "    # Построение графика изменения цены в процентах\n",
    "    fig = px.line(asset_data, x=asset_data.index, y='Price_Change_Percent', \n",
    "                  title=f'Price Change Percentage for Asset ID {asset_id}', \n",
    "                  labels={'index': 'Index', 'Price_Change_Percent': 'Price Change (%)'})\n",
    "    \n",
    "    # Показать график\n",
    "    fig.show()\n",
    "    fig.write_html(Path[\"plots\"](model_num, data_num, \"price_change_by_asset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_token_data(df, token):\n",
    "    # Фильтрация данных по выбранному токену\n",
    "    token_data = df[df['token'] == token]\n",
    "    \n",
    "    # Вычисление среднего значения net_worth для данного токена\n",
    "    avg_net_worth = token_data['net_worth'].mean()\n",
    "\n",
    "    # Создание графика\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Линия net_worth\n",
    "    fig.add_trace(go.Scatter(x=token_data['current_step'], y=token_data['net_worth'], mode='lines', name='Net Worth'))\n",
    "\n",
    "    # Горизонтальная линия для net_worth = 1000\n",
    "    fig.add_hline(y=1000, line_color=\"green\", name='Net Worth = 1000')\n",
    "\n",
    "    # Горизонтальная линия для среднего значения net_worth\n",
    "    fig.add_hline(y=avg_net_worth, line_color=\"red\", name=f'Average Net Worth = {avg_net_worth:.2f}')\n",
    "\n",
    "    # Настройка заголовков и осей\n",
    "    fig.update_layout(title=f'Net Worth and Average for {token}',\n",
    "                      xaxis_title='Current Step',\n",
    "                      yaxis_title='Net Worth')\n",
    "\n",
    "    # Показать график\n",
    "    fig.show()\n",
    "    fig.write_html(Path[\"plots\"](model_num, data_num, \"token_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_action_counts(df, token):\n",
    "    # Фильтрация данных по токену\n",
    "    token_data = df[df['token'] == token]\n",
    "    \n",
    "    # Подсчет количества каждого уникального действия для данного токена\n",
    "    action_counts = token_data['action'].value_counts().reset_index()\n",
    "    action_counts.columns = ['action', 'count']\n",
    "\n",
    "    # Построение бар-чарта для отображения количества каждого действия\n",
    "    fig = px.bar(action_counts, x='action', y='count', title=f'Count of Actions for {token}', labels={'action': 'Action', 'count': 'Count'})\n",
    "\n",
    "    # Показать график\n",
    "    fig.show()\n",
    "    fig.write_html(Path[\"plots\"](model_num, data_num, \"action_counts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relative_change_by_token(df, token):\n",
    "    # Фильтрация данных по токену\n",
    "    token_data = df[df['token'] == token].copy()\n",
    "\n",
    "    # Вычисление относительного изменения для current_price и net_worth\n",
    "    token_data['Price_Change_Percent'] = token_data['current_price'].pct_change() * 100\n",
    "    token_data['NetWorth_Change_Percent'] = token_data['net_worth'].pct_change() * 100\n",
    "\n",
    "    # Создание графика\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Линия для изменения current_price\n",
    "    fig.add_trace(go.Scatter(x=token_data['current_step'], y=token_data['Price_Change_Percent'],\n",
    "                             mode='lines', name='Current Price Change (%)'))\n",
    "\n",
    "    # Линия для изменения net_worth\n",
    "    fig.add_trace(go.Scatter(x=token_data['current_step'], y=token_data['NetWorth_Change_Percent'],\n",
    "                             mode='lines', name='Net Worth Change (%)'))\n",
    "\n",
    "    # Настройка заголовков и осей\n",
    "    fig.update_layout(title=f'Relative Change of Current Price and Net Worth for {token}',\n",
    "                      xaxis_title='Current Step',\n",
    "                      yaxis_title='Change (%)')\n",
    "\n",
    "    # Показать график\n",
    "    fig.show()\n",
    "    fig.write_html(Path[\"plots\"](model_num, data_num, \"relative_change_by_token\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAC(\n",
    "    policy='MlpPolicy',  # Use a Multi-Layer Perceptron policy\n",
    "    env=train_env,\n",
    "    verbose=1,\n",
    "    learning_rate=1e-4,  # Adjust learning rate if needed\n",
    "    batch_size=512,      # Adjust batch size if needed\n",
    "    tensorboard_log=\"./sac_tensorboard/\",  # Directory for TensorBoard logs\n",
    "    seed= seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the evaluation callback\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "eval_callback = EvalCallback(\n",
    "    test_env,                         # Evaluation environment\n",
    "    best_model_save_path= Path[\"model_save\"](model_num, data_num),   # Directory to save the best model\n",
    "    log_path= Path[\"train_log\"](model_num, data_num),               # Directory to save evaluation logs\n",
    "    eval_freq=5000,                   # Evaluate every 5000 steps\n",
    "    n_eval_episodes=3,                # Number of episodes to evaluate\n",
    "    deterministic=True,               # Use deterministic actions during evaluation\n",
    "    render=False                      # Disable rendering during evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(\n",
    "    total_timesteps=nb_steps,\n",
    "    log_interval=1000,        \n",
    "    # callback=eval_callback   \n",
    "    progress_bar= True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(Path[\"model_save\"](model_num, data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = train_env.hist\n",
    "train_hist_df = pd.DataFrame(train_hist)\n",
    "print(len(train_hist[\"action\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = train_hist_df['token'].unique()\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 20\n",
    "plot_token_data(df = train_hist_df, token = token)\n",
    "plot_close_by_asset(df= train_df, asset_id= token)\n",
    "plot_price_change_by_asset(df= train_df, asset_id= token)\n",
    "plot_relative_change_by_token(df = train_hist_df, token = token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAC.load(Path[\"model_save\"](model_num, data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = test_env.reset(reset_hist=True)  # Reset hist at the beginning\n",
    "for _ in range(len(test_df)):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        obs, info = test_env.reset(reset_hist=False)  # Do not reset hist\n",
    "        if info is None:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hist = test_env.hist\n",
    "test_hist_df = pd.DataFrame(test_hist)\n",
    "print(len(test_hist[\"action\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = test_hist_df['token'].unique()\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_token_data(df = test_hist_df, token = token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_close_by_asset(df= test_df, asset_id= token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(hist_df, test_df, initial_balance):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance.\n",
    "\n",
    "    Parameters:\n",
    "    - hist_df: DataFrame containing the testing history.\n",
    "    - test_df: DataFrame containing the test data.\n",
    "    - initial_balance: Initial balance used in the environment.\n",
    "\n",
    "    Returns:\n",
    "    - report_df: DataFrame containing performance metrics per asset.\n",
    "    - overall_metrics: Dictionary containing overall performance metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure timestamps are in order\n",
    "    hist_df = hist_df.sort_values('current_step').reset_index(drop=True)\n",
    "\n",
    "    # List of assets\n",
    "    assets = hist_df['token'].unique()\n",
    "\n",
    "    # Initialize report DataFrame\n",
    "    report = []\n",
    "\n",
    "    for asset_id in assets:\n",
    "        asset_hist = hist_df[hist_df['token'] == asset_id]\n",
    "        asset_data = test_df[test_df['Asset_ID_encoded'] == asset_id]\n",
    "\n",
    "        # Calculate total profit/loss\n",
    "        final_net_worth = asset_hist['net_worth'].iloc[-1]\n",
    "        total_profit = final_net_worth - initial_balance\n",
    "\n",
    "        # Calculate ROI\n",
    "        roi = (final_net_worth - initial_balance) / initial_balance * 100\n",
    "\n",
    "        # Calculate Sharpe Ratio\n",
    "        returns = asset_hist['net_worth'].pct_change().dropna()\n",
    "        if returns.std() != 0:\n",
    "            sharpe_ratio = (returns.mean() / returns.std()) * np.sqrt(252)  # Assuming daily data\n",
    "        else:\n",
    "            sharpe_ratio = np.nan  # Undefined if no variance\n",
    "\n",
    "        # Calculate Maximum Drawdown\n",
    "        cumulative_returns = (1 + returns).cumprod()\n",
    "        cumulative_max = cumulative_returns.cummax()\n",
    "        drawdown = (cumulative_returns - cumulative_max) / cumulative_max\n",
    "        max_drawdown = drawdown.min()\n",
    "\n",
    "        # Calculate Win Rate\n",
    "        trades = asset_hist[asset_hist['action'] != 0]\n",
    "        wins = trades[trades['net_worth'].diff() > 0]\n",
    "        win_rate = len(wins) / len(trades) * 100 if len(trades) > 0 else np.nan\n",
    "\n",
    "        # Buy-and-Hold Strategy\n",
    "        initial_price = asset_data['Close_orig'].iloc[0]\n",
    "        final_price = asset_data['Close_orig'].iloc[-1]\n",
    "        buy_and_hold_profit = (final_price - initial_price) * (initial_balance / initial_price)\n",
    "        buy_and_hold_roi = (final_price - initial_price) / initial_price * 100\n",
    "\n",
    "        # Ideal Strategy\n",
    "        min_price = asset_data['Close_orig'].min()\n",
    "        max_price = asset_data['Close_orig'].max()\n",
    "        ideal_profit = (max_price - min_price) * (initial_balance / min_price)\n",
    "        ideal_roi = (max_price - min_price) / min_price * 100\n",
    "\n",
    "        # Collect metrics\n",
    "        report.append({\n",
    "            'Asset_ID': asset_id,\n",
    "            'Total Profit': total_profit,\n",
    "            'ROI (%)': roi,\n",
    "            'Sharpe Ratio': sharpe_ratio,\n",
    "            'Max Drawdown (%)': max_drawdown * 100,\n",
    "            'Win Rate (%)': win_rate,\n",
    "            'Buy-and-Hold Profit': buy_and_hold_profit,\n",
    "            'Buy-and-Hold ROI (%)': buy_and_hold_roi,\n",
    "            'Ideal Profit': ideal_profit,\n",
    "            'Ideal ROI (%)': ideal_roi,\n",
    "            'Asset Price Change (%)': (final_price - initial_price) / initial_price * 100,\n",
    "        })\n",
    "\n",
    "    # Create DataFrame from report\n",
    "    report_df = pd.DataFrame(report)\n",
    "\n",
    "    # Calculate overall averages for each column\n",
    "    averages = report_df.mean(numeric_only=True)\n",
    "    averages['Asset_ID'] = 'Average'  # Mark row as average\n",
    "\n",
    "    # Append averages row to the DataFrame using pd.concat\n",
    "    report_df = pd.concat([report_df, pd.DataFrame([averages])], ignore_index=True)\n",
    "\n",
    "    # Calculate overall metrics\n",
    "    overall_profit = report_df['Total Profit'].sum()\n",
    "    overall_roi = (overall_profit / (initial_balance * len(assets))) * 100\n",
    "    overall_sharpe = report_df['Sharpe Ratio'].mean()\n",
    "    overall_win_rate = report_df['Win Rate (%)'].mean()\n",
    "    overall_buy_and_hold_profit = report_df['Buy-and-Hold Profit'].sum()\n",
    "    overall_buy_and_hold_roi = (overall_buy_and_hold_profit / (initial_balance * len(assets))) * 100\n",
    "\n",
    "    overall_metrics = {\n",
    "        'Total Profit': overall_profit,\n",
    "        'ROI (%)': overall_roi,\n",
    "        'Sharpe Ratio': overall_sharpe,\n",
    "        'Win Rate (%)': overall_win_rate,\n",
    "        'Buy-and-Hold Profit': overall_buy_and_hold_profit,\n",
    "        'Buy-and-Hold ROI (%)': overall_buy_and_hold_roi,\n",
    "    }\n",
    "\n",
    "    return report_df, overall_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Asset_ID: Уникальный идентификатор актива (из столбца token), для которого рассчитываются метрики.\n",
    "\n",
    "- Total Profit: Общий финансовый результат (прибыль или убыток) по данному активу. Рассчитывается как разница между конечной чистой стоимостью (net_worth) и начальным балансом (initial_balance).\n",
    "\n",
    "- ROI (%): Доходность инвестиций (Return on Investment) в процентах. Показывает процентный прирост (или убыток) от начальной суммы баланса.\n",
    "\n",
    "- Sharpe Ratio: Коэффициент Шарпа. Оценивает отношение доходности к риску (волатильности). Чем выше коэффициент Шарпа, тем лучше риск-корректированная доходность стратегии.\n",
    "\n",
    "- Max Drawdown (%): Максимальная просадка в процентах. Это максимальное снижение стоимости актива от его исторического максимума. Отражает риски стратегии, связанные с падением стоимости.\n",
    "\n",
    "- Win Rate (%): Процент прибыльных сделок. Это отношение количества прибыльных сделок к общему количеству сделок по активу, умноженное на 100.\n",
    "\n",
    "- Buy-and-Hold Profit: Прибыль при стратегии \"купить и держать\". Показывает, сколько можно было бы заработать, если просто купить актив в начале и держать его до конца периода тестирования.\n",
    "\n",
    "- Buy-and-Hold ROI (%): Доходность при стратегии \"купить и держать\". Процентный прирост от начальной цены актива, если его просто держать до конца периода.\n",
    "\n",
    "- Ideal Profit: Идеальная прибыль. Это гипотетическая максимальная прибыль, которую можно было бы получить, если бы купили актив по минимальной цене и продали по максимальной цене за период.\n",
    "\n",
    "- Ideal ROI (%): Идеальная доходность. Процентный прирост при идеальной стратегии, где покупка происходит по минимальной цене, а продажа — по максимальной.\n",
    "\n",
    "- Asset Price Change (%): Изменение цены актива в процентах за период. Это процентное изменение цены от начальной до конечной за период тестирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df, overall_metrics = evaluate_model(test_hist_df, test_df, initial_balance = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hist_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df.to_csv(Path[\"reports\"](model_num, data_num, \"test\"), index= False)\n",
    "test_hist_df.describe().to_csv(Path[\"reports\"](model_num, data_num, \"test_describe\"), index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
