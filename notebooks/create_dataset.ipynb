{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from model_config import Path\n",
    "import plotly.graph_objects as go \n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import pandas_ta as ta\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All Fiches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "timeframe = 1\n",
    "data_num = 1\n",
    "folder_path = Path[\"raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(scaler) == type(StandardScaler()):\n",
    "    scaler_name = \"Standart\"\n",
    "    \n",
    "elif type(scaler) == type(MinMaxScaler()):\n",
    "    scaler_name = \"MinMax\"\n",
    "\n",
    "elif type(scaler) == type(RobustScaler()):\n",
    "    scaler_name = \"Robust\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical features to scale\n",
    "numerical_features = [\n",
    "                    \"Close\",\n",
    "                    'Open', 'High', 'Low', 'Average',  'Change', 'Volume', 'Volume Change',\n",
    "                    'EMA', 'SMA',  'MACD', 'BB_upper', 'BB_middle', 'BB_lower'\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "dataframes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each CSV file in the folder\n",
    "for csv_file in csv_files:\n",
    "    # Construct full file path\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    df = df.iloc[1:].reset_index(drop=True)\n",
    "    \n",
    "    # Extract the Asset_ID from the file name (assuming file name is the Asset_ID)\n",
    "    asset_id = os.path.splitext(csv_file)[0].split(\"_\")[0]  # Removes the '.csv' extension\n",
    "    \n",
    "    # Add the Asset_ID column to the DataFrame\n",
    "    df['Asset_ID'] = asset_id\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка пропущенных значений\n",
    "combined_df.fillna(method='ffill', inplace=True)\n",
    "combined_df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' column to datetime if not already\n",
    "combined_df['Date'] = pd.to_datetime(combined_df['Date'])\n",
    "\n",
    "# Sort by Asset_ID and Date\n",
    "combined_df.sort_values(by=['Asset_ID', 'Date'], inplace=True)\n",
    "\n",
    "# Reset index after sorting\n",
    "combined_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.groupby('Asset_ID', group_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_indicators(group):\n",
    "    group['EMA'] = ta.ema(group['Close'], length=14)\n",
    "    group['SMA'] = ta.sma(group['Close'], length=14)\n",
    "    group['RSI'] = ta.rsi(group['Close'], length=14)\n",
    "    group['MACD'] = ta.macd(group['Close'])['MACD_12_26_9']\n",
    "    bbands = ta.bbands(group['Close'], length=20)\n",
    "    group['BB_upper'] = bbands['BBU_20_2.0']\n",
    "    group['BB_middle'] = bbands['BBM_20_2.0']\n",
    "    group['BB_lower'] = bbands['BBL_20_2.0']\n",
    "    return group\n",
    "\n",
    "# Apply the function to each group (asset)\n",
    "combined_df = combined_df.apply(add_technical_indicators)\n",
    "combined_df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time components\n",
    "combined_df['Hour'] = combined_df['Date'].dt.hour\n",
    "combined_df['Day'] = combined_df['Date'].dt.dayofweek  # 0 = Monday\n",
    "combined_df['Month'] = combined_df['Date'].dt.month\n",
    "\n",
    "# Cyclical encoding\n",
    "combined_df['Hour_sin'] = np.sin(2 * np.pi * combined_df['Hour']/24)\n",
    "combined_df['Hour_cos'] = np.cos(2 * np.pi * combined_df['Hour']/24)\n",
    "\n",
    "combined_df['Day_sin'] = np.sin(2 * np.pi * combined_df['Day']/7)\n",
    "combined_df['Day_cos'] = np.cos(2 * np.pi * combined_df['Day']/7)\n",
    "\n",
    "combined_df['Month_sin'] = np.sin(2 * np.pi * combined_df['Month']/12)\n",
    "combined_df['Month_cos'] = np.cos(2 * np.pi * combined_df['Month']/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "combined_df['Asset_ID_encoded'] = label_encoder.fit_transform(combined_df['Asset_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"Close_orig\"] = combined_df[\"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(df, scaler):\n",
    "    if scaler in [\"log\"]:\n",
    "        def scale_group(group):\n",
    "            # Применяем логарифмическую трансформацию к числовым признакам\n",
    "            group[numerical_features] = np.log(group[numerical_features] + 1e-6)  # Добавляем небольшое значение для избежания логарифма от 0\n",
    "            return group\n",
    "    else:\n",
    "        def scale_group(group):\n",
    "            group[numerical_features] = scaler.fit_transform(group[numerical_features])\n",
    "            return group  \n",
    "\n",
    "    df = df.groupby('Asset_ID', group_keys=False).apply(scale_group).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = scale_data(df = combined_df, scaler= scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для замены нулей на среднее\n",
    "def replace_zeros_with_mean(df, columns):\n",
    "    for column in columns:\n",
    "        df[column].replace(0, np.nan, inplace=True)\n",
    "        df[column].interpolate(method='linear', inplace=True)\n",
    "        df[column].fillna(method='bfill', inplace=True)\n",
    "        df[column].fillna(method='ffill', inplace=True)\n",
    "    return df\n",
    "\n",
    "# Задаем столбцы, в которых нужно заменить нули\n",
    "columns_to_replace = [ \n",
    "                      \"Close_orig\",   \n",
    "                      \"Close\", 'Open', 'High', 'Low', 'Average',  'Change', 'Volume', 'Volume Change',\n",
    "                      'EMA', 'SMA', 'RSI', 'MACD', 'BB_upper', 'BB_middle', 'BB_lower'\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Замена нулевых значений на средние с интерполяцией для каждого Asset_ID\n",
    "combined_df = combined_df.groupby('Asset_ID', group_keys=False).apply(lambda group: replace_zeros_with_mean(group, columns_to_replace)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_close_prices = combined_df[combined_df['Close'] == 0]\n",
    "print(f\"Number of zero 'Close' prices after scaling: {len(zero_close_prices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.sort_values(by=['Asset_ID', 'Date'], inplace=True)\n",
    "combined_df.drop(columns= ['Date', \"Asset_ID\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) scaler\n",
    "2) columns cnt\n",
    "3) tokens cnt\n",
    "4) timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_cnt = combined_df.shape[1]\n",
    "tokens_cnt = len(combined_df['Asset_ID_encoded'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(Path[\"dataset\"](data_num, scaler_name, columns_cnt, tokens_cnt, timeframe), index= False)\n",
    "print(f\"File saved to {Path['dataset'](data_num, scaler_name, columns_cnt, tokens_cnt, timeframe)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path[\"dataset\"](data_num, scaler_name, columns_cnt, tokens_cnt, timeframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
